from typing import List, Union
from langchain_experimental.tools import PythonAstREPLTool
from langchain_teddynote import logging
from langchain_teddynote.messages import AgentStreamParser, AgentCallbacks
from dotenv import load_dotenv
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

##### í°íŠ¸ ì„¤ì • #####
import platform

# OS íŒë‹¨
current_os = platform.system()

if current_os == "Windows":
    # Windows í™˜ê²½ í°íŠ¸ ì„¤ì •
    font_path = "C:/Windows/Fonts/malgun.ttf"  # ë§‘ì€ ê³ ë”• í°íŠ¸ ê²½ë¡œ
    fontprop = fm.FontProperties(fname=font_path, size=12)
    plt.rc("font", family=fontprop.get_name())
elif current_os == "Darwin":  # macOS
    # Mac í™˜ê²½ í°íŠ¸ ì„¤ì •
    plt.rcParams["font.family"] = "AppleGothic"
else:  # Linux ë“± ê¸°íƒ€ OS
    # ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
    try:
        plt.rcParams["font.family"] = "NanumGothic"
    except:
        print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

##### ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€ #####
plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

# API í‚¤ ë° í”„ë¡œì íŠ¸ ì„¤ì •
load_dotenv()
logging.langsmith("CSV Agent ì±—ë´‡")

# Streamlit ì•± ì„¤ì •
st.title("CSV ë°ì´í„° ë¶„ì„ ì±—ë´‡ ğŸ’¬")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []  # ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”


# ìƒìˆ˜ ì •ì˜
class MessageRole:
    """
    ë©”ì‹œì§€ ì—­í• ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    USER = "user"  # ì‚¬ìš©ì ë©”ì‹œì§€ ì—­í• 
    ASSISTANT = "assistant"  # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì—­í• 


class MessageType:
    """
    ë©”ì‹œì§€ ìœ í˜•ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    TEXT = "text"  # í…ìŠ¤íŠ¸ ë©”ì‹œì§€
    FIGURE = "figure"  # ê·¸ë¦¼ ë©”ì‹œì§€
    CODE = "code"  # ì½”ë“œ ë©”ì‹œì§€
    DATAFRAME = "dataframe"  # ë°ì´í„°í”„ë ˆì„ ë©”ì‹œì§€


# ë©”ì‹œì§€ ê´€ë ¨ í•¨ìˆ˜
def print_messages():
    """
    ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    for role, content_list in st.session_state["messages"]:
        with st.chat_message(role):
            for content in content_list:
                if isinstance(content, list):
                    message_type, message_content = content
                    if message_type == MessageType.TEXT:
                        st.markdown(message_content)  # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.FIGURE:
                        st.pyplot(message_content)  # ê·¸ë¦¼ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.CODE:
                        with st.status("ì½”ë“œ ì¶œë ¥", expanded=False):
                            st.code(
                                message_content, language="python"
                            )  # ì½”ë“œ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.DATAFRAME:
                        st.dataframe(message_content)  # ë°ì´í„°í”„ë ˆì„ ë©”ì‹œì§€ ì¶œë ¥
                else:
                    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì½˜í…ì¸  ìœ í˜•: {content}")


def add_message(role: MessageRole, content: List[Union[MessageType, str]]):
    """
    ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        role (MessageRole): ë©”ì‹œì§€ ì—­í•  (ì‚¬ìš©ì ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸)
        content (List[Union[MessageType, str]]): ë©”ì‹œì§€ ë‚´ìš©
    """
    messages = st.session_state["messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])  # ê°™ì€ ì—­í• ì˜ ì—°ì†ëœ ë©”ì‹œì§€ëŠ” í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤
    else:
        messages.append([role, [content]])  # ìƒˆë¡œìš´ ì—­í• ì˜ ë©”ì‹œì§€ëŠ” ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤


# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")  # ëŒ€í™” ë‚´ìš©ì„ ì´ˆê¸°í™”í•˜ëŠ” ë²„íŠ¼
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.", type=["csv"]
    )  # CSV íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
    selected_model = st.selectbox(
        "OpenAI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", ["gpt-4o", "gpt-4o-mini"], index=0
    )  # OpenAI ëª¨ë¸ ì„ íƒ ì˜µì…˜

    user_column_guideline = st.text_area("ì»¬ëŸ¼ ê°€ì´ë“œë¼ì¸")

    apply_btn = st.button("ë°ì´í„° ë¶„ì„ ì‹œì‘")  # ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•˜ëŠ” ë²„íŠ¼

    txt_column_guideline = st.empty()


# ì½œë°± í•¨ìˆ˜
def tool_callback(tool) -> None:
    """
    ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        tool (dict): ì‹¤í–‰ëœ ë„êµ¬ ì •ë³´
    """
    if tool_name := tool.get("tool"):
        if tool_name == "python_repl_tool":
            tool_input = tool.get("tool_input", {})
            query = tool_input.get("code")
            if query:
                df_in_result = None
                with st.status("ë°ì´í„° ë¶„ì„ ì¤‘...", expanded=True) as status:
                    st.markdown(f"```python\n{query}\n```")
                    add_message(MessageRole.ASSISTANT, [MessageType.CODE, query])
                    if "df" in st.session_state:
                        result = st.session_state["python_tool"].invoke(
                            {"query": query}
                        )
                        if isinstance(result, pd.DataFrame):
                            df_in_result = result
                    status.update(label="ì½”ë“œ ì¶œë ¥", state="complete", expanded=False)

                if df_in_result is not None:
                    st.dataframe(df_in_result)
                    add_message(
                        MessageRole.ASSISTANT, [MessageType.DATAFRAME, df_in_result]
                    )

                if "plt.show" in query:
                    fig = plt.gcf()
                    st.pyplot(fig)
                    add_message(MessageRole.ASSISTANT, [MessageType.FIGURE, fig])

                return result
            else:
                st.error(
                    "ë°ì´í„°í”„ë ˆì„ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                )
                return


def observation_callback(observation) -> None:
    """
    ê´€ì°° ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        observation (dict): ê´€ì°° ê²°ê³¼
    """
    if "observation" in observation:
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(obs)
            st.session_state["messages"][-1][
                1
            ].clear()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚­ì œ


def result_callback(result: str) -> None:
    """
    ìµœì¢… ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        result (str): ìµœì¢… ê²°ê³¼
    """
    pass  # í˜„ì¬ëŠ” ì•„ë¬´ ë™ì‘ë„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤


# ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
def create_agent(
    dataframe,
    selected_model="gpt-4o",
    prefix_prompt=None,
    postfix_prompt=None,
    user_column_guideline=None,
):
    """
    ë°ì´í„°í”„ë ˆì„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        dataframe (pd.DataFrame): ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„
        selected_model (str, optional): ì‚¬ìš©í•  OpenAI ëª¨ë¸. ê¸°ë³¸ê°’ì€ "gpt-4o"

    Returns:
        Agent: ìƒì„±ëœ ë°ì´í„°í”„ë ˆì„ ì—ì´ì „íŠ¸
    """
    from dataanalysis import DataAnalysisAgent

    return DataAnalysisAgent(
        dataframe,
        model_name=selected_model,
        prefix_prompt=prefix_prompt,
        postfix_prompt=postfix_prompt,
        column_guideline=user_column_guideline,
    )


# ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def ask(query):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸
    """
    if "agent" in st.session_state:
        st.chat_message("user").write(query)
        add_message(MessageRole.USER, [MessageType.TEXT, query])

        agent = st.session_state["agent"]
        response = agent.stream(query, "abc123")

        ai_answer = ""
        parser_callback = AgentCallbacks(
            tool_callback, observation_callback, result_callback
        )
        stream_parser = AgentStreamParser(parser_callback)

        with st.chat_message("assistant"):
            for step in response:
                stream_parser.process_agent_steps(step)
                if "output" in step:
                    ai_answer += step["output"]
            st.write(ai_answer)

        add_message(MessageRole.ASSISTANT, [MessageType.TEXT, ai_answer])


# ë©”ì¸ ë¡œì§
if clear_btn:
    st.session_state["messages"] = []  # ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”

if apply_btn and uploaded_file:
    loaded_data = pd.read_csv(uploaded_file)  # CSV íŒŒì¼ ë¡œë“œ
    st.session_state["df"] = loaded_data  # ë°ì´í„°í”„ë ˆì„ ì €ì¥
    st.session_state["python_tool"] = PythonAstREPLTool()  # Python ì‹¤í–‰ ë„êµ¬ ìƒì„±
    st.session_state["python_tool"].locals[
        "df"
    ] = loaded_data  # ë°ì´í„°í”„ë ˆì„ì„ Python ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€
    st.session_state["agent"] = create_agent(
        loaded_data,
        selected_model,
        prefix_prompt=None,
        postfix_prompt=None,
        user_column_guideline=user_column_guideline,
    )  # ì—ì´ì „íŠ¸ ìƒì„±

    st.success("ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•´ ì£¼ì„¸ìš”!")
elif apply_btn:
    st.warning("íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")


if "agent" in st.session_state:
    updated_column_guideline = txt_column_guideline.markdown(
        f"**ì»¬ëŸ¼ ê°€ì´ë“œë¼ì¸**\n\n```\n{st.session_state['agent'].column_guideline}\n```"
    )

print_messages()  # ì €ì¥ëœ ë©”ì‹œì§€ ì¶œë ¥

user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if user_input:
    ask(user_input)  # ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
