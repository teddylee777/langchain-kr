{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f18febf",
   "metadata": {},
   "source": [
    "설치된 openai 의 버전을 체크합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## ChatOpenAI\n",
    "\n",
    "OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\n",
    "\n",
    "객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\n",
    "\n",
    "`temperature`\n",
    "\n",
    "- 사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\n",
    "\n",
    "`max_tokens`\n",
    "\n",
    "- 채팅 완성에서 생성할 토큰의 최대 개수입니다.\n",
    "\n",
    "`model_name`: 적용 가능한 모델 리스트\n",
    "\n",
    "- 링크: https://platform.openai.com/docs/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d74d9",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8aedc",
   "metadata": {},
   "source": [
    "`PromptTemplate`\n",
    "\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\n",
    "- 사용법\n",
    "  - `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\n",
    "- 사용법: 리스트 형식으로 변수 이름을 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = \"{country}의 수도는 뭐야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d700a6e",
   "metadata": {},
   "source": [
    "### LLMChain 객체\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cc045",
   "metadata": {},
   "source": [
    "`LLMChain`\n",
    "\n",
    "- LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\n",
    "- 사용법\n",
    "  - `prompt`: 앞서 정의한 PromptTemplate 객체를 사용합니다.\n",
    "  - `llm`: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6369fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd692f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"country\": \"캐나다\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9a157",
   "metadata": {},
   "source": [
    "### apply()\n",
    "\n",
    "`apply()` 함수로 여러개의 입력에 대한 처리를 한 번에 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\": \"네덜란드\"}]\n",
    "\n",
    "response = llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622efee7",
   "metadata": {},
   "source": [
    "`text` 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\n",
    "\n",
    "이를 반복문으로 출력한다면 다음과 같습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_list 에 대한 결과 반환\n",
    "result = llm_chain.apply(input_list)\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "for res in result:\n",
    "    print(res[\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38852a",
   "metadata": {},
   "source": [
    "### `generate()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd758206",
   "metadata": {},
   "source": [
    "`generate()` 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\n",
    "\n",
    "LLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값\n",
    "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\": \"네덜란드\"}]\n",
    "\n",
    "# input_list 에 대한 결과 반환\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59487318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 사용량 출력\n",
    "generated_result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a99eed",
   "metadata": {},
   "source": [
    "### 2개 이상의 변수를 템플릿 안에 정의\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b1093",
   "metadata": {},
   "source": [
    "2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\n",
    "\n",
    "이번에는 2개 이상의 변수(`input_variables`) 를 활용하여 템플릿 구성을 해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = \"{area1} 와 {area2} 의 시차는 몇시간이야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc451ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3533451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행: run()\n",
    "print(llm_chain.invoke({\"area1\": \"서울\", \"area2\": \"파리\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaa1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    {\"area1\": \"파리\", \"area2\": \"뉴욕\"},\n",
    "    {\"area1\": \"서울\", \"area2\": \"하와이\"},\n",
    "    {\"area1\": \"켄버라\", \"area2\": \"베이징\"},\n",
    "]\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "result = llm_chain.apply(input_list)\n",
    "for res in result:\n",
    "    print(res[\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef6054",
   "metadata": {},
   "source": [
    "## stream: 실시간 출력\n",
    "\n",
    "스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\n",
    "\n",
    "다음과 같이 `streaming=True` 로 설정하고 스트리밍으로 답변을 받기 위한 `StreamingStdOutCallbackHandler()` 을 콜백으로 지정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d721f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국에 대해서 300자 내외로 최대한 상세히 알려줘\"\n",
    "\n",
    "# 스트리밍으로 답변 출력\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b23e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
