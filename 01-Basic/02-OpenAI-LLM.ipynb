{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## ChatOpenAI\n",
    "\n",
    "OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\n",
    "\n",
    "객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\n",
    "\n",
    "`temperature`\n",
    "\n",
    "- 사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\n",
    "\n",
    "`max_tokens`\n",
    "\n",
    "- 채팅 완성에서 생성할 토큰의 최대 개수입니다.\n",
    "\n",
    "`model_name`: 적용 가능한 모델 리스트\n",
    "- `gpt-3.5-turbo`\n",
    "- `gpt-4-turbo`\n",
    "- `gpt-4o`\n",
    "\n",
    "![gpt-models.png](./images/gpt-models.png)\n",
    "\n",
    "- 링크: https://platform.openai.com/docs/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef2647",
   "metadata": {},
   "source": [
    "### 답변의 형식(AI Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af58a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd49c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df69214",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4a51a",
   "metadata": {},
   "source": [
    "### LogProb 활성화\n",
    "\n",
    "주어진 텍스트에 대한 모델의 **토큰 확률의 로그 값** 을 의미합니다. 토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 **모델이 그 토큰을 예측할 확률**을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe733438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ").bind(logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec3e6",
   "metadata": {},
   "source": [
    "### 스트리밍 출력\n",
    "\n",
    "스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트림 방식으로 질의\n",
    "# answer 에 스트리밍 답변의 결과를 받습니다.\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a90e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 스트림 방식으로 질의\n",
    "# answer 에 스트리밍 답변의 결과를 받습니다.\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95ce8b",
   "metadata": {},
   "source": [
    "## 멀티모달 모델(이미지 인식)\n",
    "\n",
    "멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미합니다. 이는 다음과 같은 다양한 데이터 유형을 포함할 수 있습니다.\n",
    "\n",
    "- 텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보\n",
    "- 이미지: 사진, 그래픽, 그림 등 시각적 정보\n",
    "- 오디오: 음성, 음악, 소리 효과 등의 청각적 정보\n",
    "- 비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합\n",
    "\n",
    "`gpt-4o` 나 `gpt-4-turbo` 모델은 이미지 인식 기능(Vision) 이 추가되어 있는 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")\n",
    "\n",
    "# 멀티모달 객체 생성\n",
    "multimodal_llm = MultiModal(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 주소(웹사이트로 부터 바로 인식)\n",
    "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\n",
    "\n",
    "# 이미지 파일로 부터 질의\n",
    "answer = multimodal_llm.stream(IMAGE_URL)\n",
    "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 PC 에 저장되어 있는 이미지의 경로 입력\n",
    "IMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"\n",
    "\n",
    "# 이미지 파일로 부터 질의(스트림 방식)\n",
    "answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\n",
    "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5fc02",
   "metadata": {},
   "source": [
    "## System, User 프롬프트 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be092af",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다. \n",
    "당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다. 흥미로운 사실을 정리하여 답변하세요.\"\"\"\n",
    "\n",
    "# 멀티모달 객체 생성\n",
    "multimodal_llm_with_prompt = MultiModal(\n",
    "    llm, system_prompt=system_prompt, user_prompt=user_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51735d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 PC 에 저장되어 있는 이미지의 경로 입력\n",
    "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\n",
    "\n",
    "# 이미지 파일로 부터 질의(스트림 방식)\n",
    "answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
