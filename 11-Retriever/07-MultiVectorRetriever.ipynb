{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96a9939",
   "metadata": {},
   "source": [
    "# 다중 벡터저장소 검색기(MultiVectorRetriever)\n",
    "\n",
    "LangChain에서는 문서를 다양한 상황에서 효율적으로 쿼리할 수 있는 특별한 기능, 바로 `MultiVectorRetriever`를 제공합니다. 이 기능을 사용하면 문서를 여러 벡터로 저장하고 관리할 수 있어, 정보 검색의 정확도와 효율성을 대폭 향상시킬 수 있습니다. 오늘은 이 `MultiVectorRetriever`를 활용해 문서당 여러 벡터를 생성하는 몇 가지 방법을 살펴보겠습니다.\n",
    "\n",
    "**문서당 여러 벡터 생성 방법 소개**\n",
    "\n",
    "1. **작은 청크 생성**: 문서를 더 작은 단위로 나눈 후, 각 청크에 대해 별도의 임베딩을 생성합니다. 이 방식을 사용하면 문서의 특정 부분에 좀 더 세심한 주의를 기울일 수 있습니다. 이 과정은 `ParentDocumentRetriever`를 통해 구현할 수 있어, 세부 정보에 대한 탐색이 용이해집니다.\n",
    "\n",
    "2. **요약 임베딩**: 각 문서의 요약을 생성하고, 이 요약으로부터 임베딩을 만듭니다. 이 요약 임베딩은 문서의 핵심 내용을 신속하게 파악하는 데 큰 도움이 됩니다. 문서 전체를 분석하는 대신 핵심적인 요약 부분만을 활용하여 효율성을 극대화할 수 있습니다.\n",
    "\n",
    "3. **가설 질문 활용**: 각 문서에 대해 적합한 가설 질문을 만들고, 이 질문에 기반한 임베딩을 생성합니다. 특정 주제나 내용에 대해 깊이 있는 탐색을 원할 때 이 방법이 유용합니다. 가설 질문은 문서의 내용을 다양한 관점에서 접근하게 해주며, 더 광범위한 이해를 가능하게 합니다.\n",
    "\n",
    "4. **수동 추가 방식**: 사용자가 문서 검색 시 고려해야 할 특정 질문이나 쿼리를 직접 추가할 수 있습니다. 이 방법을 통해 사용자는 검색 과정에서 보다 세밀한 제어를 할 수 있으며, 자신의 요구 사항에 맞춘 맞춤형 검색이 가능해집니다.\n",
    "\n",
    "`MultiVectorRetriever`를 통해 이러한 다양한 접근 방식을 유연하게 활용함으로써, 사용자는 필요한 정보를 보다 정확하고 빠르게 찾을 수 있습니다. LangChain의 이 기능은 정보 검색 작업을 보다 효과적으로 만들어주는 훌륭한 도구입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384bc267",
   "metadata": {},
   "source": [
    "## 사용 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574ec5",
   "metadata": {},
   "source": [
    "텍스트 파일에서 데이터를 로드하고, 로드된 문서들을 지정된 크기로 분할하는 전처리 과정을 수행합니다.\n",
    "\n",
    "분할된 문서들은 추후 벡터화 및 검색 등의 작업에 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "loaders = [\n",
    "    # 첫 번째 데이터를 로드합니다.\n",
    "    TextLoader(\"./data/ai-story.txt\"),\n",
    "    # 두 번째 데이터를 로드합니다.\n",
    "    TextLoader(\"./data/appendix-keywords.txt\"),\n",
    "]\n",
    "docs = []  # 빈 문서 리스트를 초기화합니다.\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())  # 각 로더에서 문서를 로드하여 docs 리스트에 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453afd1e",
   "metadata": {},
   "source": [
    "데이터로부터 로드한 원본 도큐먼트는 `docs` 변수에 담았습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b671d6e",
   "metadata": {},
   "source": [
    "## 작은 청크 생성\n",
    "\n",
    "대용량 정보를 검색하는 경우, 더 작은 단위로 정보를 임베딩하는 것이 유용할 수 있습니다.\n",
    "\n",
    "이를 통해 임베딩은 의미론적 의미를 최대한 근접하게 포착하면서도, 가능한 한 많은 맥락을 하위 단계로 전달할 수 있습니다.\n",
    "\n",
    "`ParentDocumentRetriever`가 수행하는 작업이 바로 이것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7f0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc51c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72cda610-ea10-4953-b6c5-92bbfc6d5afd',\n",
       " '2d5252a7-3080-42c9-8cbe-6bf625d41c9f']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "import uuid\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "# 두개의 생성된 id를 확인합니다.\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3e771",
   "metadata": {},
   "source": [
    "여기서 큰 청크로 분할하기 위한 `parent_text_splitter`\n",
    "\n",
    "더 작은 청크로 분할하기 위한 `child_text_splitter` 를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc95363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체를 생성합니다.\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000)\n",
    "\n",
    "# 더 작은 청크를 생성하는 데 사용할 분할기\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e48a98",
   "metadata": {},
   "source": [
    "- `parent_text_splitter`를 사용하여 문서를 큰 청크 단위로 분할합니다.\n",
    "- 각 문서의 메타데이터에 `\"doc_id\"`를 키로 하고 생성한 `uuid` 를 입력합니다.\n",
    "- 최종적으로 `parent_docs` 리스트에는 원본 문서들이 큰 단위로 분할된 하위 문서들이 저장되며, 각 문서에는 원본 문서의 ID가 메타데이터로 포함됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4437c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]  # 현재 문서의 ID를 가져옵니다.\n",
    "    # 현재 문서를 하위 문서로 분할합니다.\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "    for _doc in parent_doc:  # 분할된 문서에 대해 반복합니다.\n",
    "        # 문서의 메타데이터에 ID를 저장합니다.\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)  # 분할된 문서를 리스트에 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f680da0",
   "metadata": {},
   "source": [
    "- `child_text_splitter`를 사용하여 문서를 더 작은 청크로 분할합니다.\n",
    "- 각 문서의 메타데이터에 `\"doc_id\"`를 키로 하고 생성한 `uuid` 를 입력합니다. 이는 작게 분할된 청크에 문서의 ID 를 부여하기 위함입니다.\n",
    "- 최종적으로 `child_docs` 리스트에는 원본 문서들이 작게 분할된 하위 문서들이 저장되며, 각 하위 문서에는 원본 문서의 ID가 메타데이터로 포함됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56afe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []  # 하위 문서를 저장할 리스트를 초기화합니다.\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]  # 현재 문서의 ID를 가져옵니다.\n",
    "    # 현재 문서를 하위 문서로 분할합니다.\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:  # 분할된 하위 문서에 대해 반복합니다.\n",
    "        # 하위 문서의 메타데이터에 ID를 저장합니다.\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)  # 분할된 하위 문서를 리스트에 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a346a79",
   "metadata": {},
   "source": [
    "각각 분할된 청크의 수를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfd9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 parent_docs의 개수: 4\n",
      "분할된 child_docs의 개수: 54\n"
     ]
    }
   ],
   "source": [
    "print(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\n",
    "print(f\"분할된 child_docs의 개수: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6ab64",
   "metadata": {},
   "source": [
    "벡터저장소에 새롭게 생성한 작게 쪼개진 하위문서 집합을 추가합니다.\n",
    "\n",
    "다음으로는 상위 문서는 생성한 UUID 와 맵핑하여 `docstore` 에 추가합니다.\n",
    "\n",
    "- `mset()` 메서드를 통해 문서 ID와 문서 내용을 key-value 쌍으로 문서 저장소에 저장합니다.\n",
    "\n",
    "(예시) `list(zip(doc_ids, docs))[0]`\n",
    "\n",
    "```\n",
    "('36d475a5-9f1a-40ab-aeb1-ba720fa229d8',\n",
    " Document(page_content='Scikit Learn\\n\\nScikit-learn은 Python 언어를 위한 또 다른 핵심 라이브러리로, 기계 학습의 다양한 알고리즘을 구현하기 위해 설계되었습니다. 이 라이브러리는 2007년 David Cournapeau에 의해 프로젝트가 시작되었으며, 그 후로 커뮤니티의 광범위한 기여를 받아 현재까지 발전해왔습니다. ...))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a291a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 하위 문서를 추가합니다.\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# 문서 저장소에 문서 ID와 문서를 매핑하여 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a644c1",
   "metadata": {},
   "source": [
    "주어진 키워드에 대한 유사도 검색을 수행합니다. 가장 유사도가 높은 첫 번째 문서 조각을 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d9ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Word2Vec의 성공 이후, 이와 유사한 다른 단어 임베딩 기법들도 개발되었습니다. 그러나 Word2Vec은 그 간결함과 효율성, 높은 성능으로 인해 여전히 광범위하게 사용되며, NLP 분야에서 기본적인 도구로 자리 잡았습니다. Word2Vec는 단순한 텍스트 데이터를 통해 복잡한 언어의 의미 구조를 학습할 수 있는 강력한 방법을 제공함으로써, 컴퓨터가 인간 언어를 이해하는 방식을 혁신적으로 개선하였습니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       " Document(page_content='Word2Vec은 크게 두 가지 모델 아키텍처로 구성됩니다: Continuous Bag-of-Words (CBOW)와 Skip-Gram입니다. CBOW 모델은 주변 단어(맥락)를 기반으로 특정 단어를 예측하는 반면, Skip-Gram 모델은 하나의 단어로부터 주변 단어들을 예측합니다. 두 모델 모두 딥러닝이 아닌, 단순화된 신경망 구조를 사용하여 대규모 텍스트 데이터에서 학습할 수 있으며, 매우 효율적입니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       " Document(page_content='Word2Vec의 벡터 표현은 다양한 NLP 작업에 활용될 수 있습니다. 예를 들어, 단어의 유사도 측정, 문장이나 문서의 벡터 표현 생성, 기계 번역, 감정 분석 등이 있습니다. 또한, 벡터 연산을 통해 단어 간의 의미적 관계를 추론하는 것이 가능해집니다. 예를 들어, \"king\" - \"man\" + \"woman\"과 같은 벡터 연산을 수행하면, 결과적으로 \"queen\"과 유사한 벡터를 가진 단어를 찾을 수 있습니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       " Document(page_content='Crawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec\\n\\n정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)', metadata={'doc_id': '2d5252a7-3080-42c9-8cbe-6bf625d41c9f', 'source': './data/appendix-keywords.txt'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorstore의 유사도 검색을 수행합니다.\n",
    "retriever.vectorstore.similarity_search(\"Word2Vec 의 정의?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa14866",
   "metadata": {},
   "source": [
    "다음과 같이 `score_threshold` 를 추가하여 유사도 검색을 수행할 수 있습니다.\n",
    "\n",
    "유사도 검색 결과에 유사도 점수가 0.5 이상인 결과만 반환합니다.\n",
    "\n",
    "또한, `k` 의 계수도 지정할 수 있으며, `k` 는 검색되는 문서의 개수를 의미합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562e5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Word2Vec의 성공 이후, 이와 유사한 다른 단어 임베딩 기법들도 개발되었습니다. 그러나 Word2Vec은 그 간결함과 효율성, 높은 성능으로 인해 여전히 광범위하게 사용되며, NLP 분야에서 기본적인 도구로 자리 잡았습니다. Word2Vec는 단순한 텍스트 데이터를 통해 복잡한 언어의 의미 구조를 학습할 수 있는 강력한 방법을 제공함으로써, 컴퓨터가 인간 언어를 이해하는 방식을 혁신적으로 개선하였습니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       "  0.8502118705599201),\n",
       " (Document(page_content='Word2Vec은 크게 두 가지 모델 아키텍처로 구성됩니다: Continuous Bag-of-Words (CBOW)와 Skip-Gram입니다. CBOW 모델은 주변 단어(맥락)를 기반으로 특정 단어를 예측하는 반면, Skip-Gram 모델은 하나의 단어로부터 주변 단어들을 예측합니다. 두 모델 모두 딥러닝이 아닌, 단순화된 신경망 구조를 사용하여 대규모 텍스트 데이터에서 학습할 수 있으며, 매우 효율적입니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       "  0.843839109014391),\n",
       " (Document(page_content='Word2Vec의 벡터 표현은 다양한 NLP 작업에 활용될 수 있습니다. 예를 들어, 단어의 유사도 측정, 문장이나 문서의 벡터 표현 생성, 기계 번역, 감정 분석 등이 있습니다. 또한, 벡터 연산을 통해 단어 간의 의미적 관계를 추론하는 것이 가능해집니다. 예를 들어, \"king\" - \"man\" + \"woman\"과 같은 벡터 연산을 수행하면, 결과적으로 \"queen\"과 유사한 벡터를 가진 단어를 찾을 수 있습니다.', metadata={'doc_id': '72cda610-ea10-4953-b6c5-92bbfc6d5afd', 'source': './data/ai-story.txt'}),\n",
       "  0.8371520268093797)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score_threshold를 사용하여 유사도 검색을 수행합니다.\n",
    "retriever.vectorstore.similarity_search_with_relevance_scores(\n",
    "    \"Word2Vec 의 정의?\", score_threshold=0.5, k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae24a1",
   "metadata": {},
   "source": [
    "`retriever` 객체의 `get_relevant_documents` 메서드를 호출하여 관련된 문서를 검색합니다.\n",
    "\n",
    "주어진 쿼리에 관련성이 높은 문서를 검색합니다.\n",
    "\n",
    "여기서는 2개의 도큐먼트 안에 \"Word2Vec\" 의 정의가 포함되었기 때문에 2개의 문서 모두 검색 결과로 나왔습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a29f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc = retriever.get_relevant_documents(\"Word2Vec 의 정의?\")\n",
    "len(relevant_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443ace4",
   "metadata": {},
   "source": [
    "첫 번째로 찾은 문서의 내용의 문자열 길이를 확인하면 문서 전체가 출력됨을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever가 반환하는 문서의 길이를 확인합니다.\n",
    "len(retriever.get_relevant_documents(\"Word2Vec 의 정의?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc30896",
   "metadata": {},
   "source": [
    "리트리버(retriever)가 벡터 데이터베이스에서 기본적으로 수행하는 검색 유형은 유사도 검색입니다.\n",
    "\n",
    "LangChain Vector Stores는 [Max Marginal Relevance](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search)를 통한 검색도 지원하므로, 이를 대신 사용하고 싶다면 다음과 같이 `search_type` 속성을 설정하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac718689",
   "metadata": {},
   "source": [
    "- `retriever` 객체의 `search_type` 속성을 `SearchType.mmr`로 설정합니다.\n",
    "  - 이는 검색 시 MMR(Maximal Marginal Relevance) 알고리즘을 사용하도록 지정하는 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# 검색어로 관련 문서를 검색하고, 첫 번째 문서의 페이지 내용 길이를 반환\n",
    "len(retriever.get_relevant_documents(\"Word2Vec의 정의\")[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d961b6c",
   "metadata": {},
   "source": [
    "## 요약본(summary)을 벡터저장소에 저장\n",
    "\n",
    "요약은 종종 청크(chunk)의 내용을 보다 정확하게 추출할 수 있어 더 나은 검색 결과를 얻을 수 있습니다.\n",
    "\n",
    "여기서는 요약을 생성하는 방법과 이를 임베딩하는 방법에 대해 설명합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}  # 입력 데이터에서 페이지 내용을 추출하는 함수\n",
    "    # 문서 요약을 위한 프롬프트 템플릿 생성\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Summarize the following document in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    # OpenAI의 ChatGPT 모델을 사용하여 요약 생성 (최대 재시도 횟수: 0)\n",
    "    | ChatOpenAI(max_retries=0)\n",
    "    | StrOutputParser()  # 생성된 요약 결과를 문자열로 파싱\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b79165",
   "metadata": {},
   "source": [
    "- `chain.batch` 메서드를 사용하여 `docs` 리스트의 문서들을 일괄 처리합니다.\n",
    "- 여기서 `max_concurrency` 매개변수를 5로 설정하여 최대 5개의 문서를 동시에 처리할 수 있도록 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 동시성을 5로 설정하여 문서 배치 처리\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a11208",
   "metadata": {},
   "source": [
    "요약된 내용을 출력하여 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약을 출력합니다.\n",
    "print(summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약을 출력합니다.\n",
    "print(summaries[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da5865",
   "metadata": {},
   "source": [
    "`Chroma` 벡터 저장소를 초기화하여 자식 청크(child chunks)를 인덱싱합니다. 이때 `OpenAIEmbeddings`를 임베딩 함수로 사용합니다.\n",
    "\n",
    "- 문서 ID를 나타내는 키로 `\"doc_id\"`를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 정보를 저장할 벡터 저장소를 생성합니다.\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
    "# 부모 문서를 저장할 저장소를 생성합니다.\n",
    "store = InMemoryByteStore()\n",
    "# 문서 ID를 저장할 키 이름을 지정합니다.\n",
    "id_key = \"doc_id\"\n",
    "# 검색기를 초기화합니다. (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,  # 벡터 저장소\n",
    "    byte_store=store,  # 바이트 저장소\n",
    "    id_key=id_key,  # 문서 ID 키\n",
    ")\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e2c6",
   "metadata": {},
   "source": [
    "요약된 문서와 메타데이터(여기서는 생성한 요약본에 대한 `Document ID` 입니다)를 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec99148",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # 요약된 내용을 페이지 콘텐츠로 하고, 문서 ID를 메타데이터로 포함하는 Document 객체를 생성합니다.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(\n",
    "        summaries\n",
    "    )  # summaries 리스트의 각 요약과 인덱스에 대해 반복합니다.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb07ac1",
   "metadata": {},
   "source": [
    "요약본의 문서의 개수는 원본 문서의 개수와 일치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약본의 문서의 개수\n",
    "len(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400de8c",
   "metadata": {},
   "source": [
    "- `retriever.vectorstore.add_documents(summary_docs)`를 통해 `summary_docs`를 벡터 저장소에 추가합니다.\n",
    "- `retriever.docstore.mset(list(zip(doc_ids, docs)))`를 사용하여 `doc_ids`와 `docs`를 매핑하여 문서 저장소에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # 요약된 문서를 벡터 저장소에 추가합니다.\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f120d85",
   "metadata": {},
   "source": [
    "다음으로는 원본 청크(chunk) 데이터를 벡터 저장소에 추가하는 코드입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체를 생성합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "\n",
    "split_docs = []\n",
    "split_docs_ids = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]  # 현재 문서의 ID를 가져옵니다.\n",
    "    # 현재 문서를 하위 문서로 분할합니다.\n",
    "    split_doc = text_splitter.split_documents([doc])\n",
    "    for _doc in split_doc:  # 분할된 문서에 대해 반복합니다.\n",
    "        # 문서의 메타데이터에 ID를 저장합니다.\n",
    "        _doc.metadata[id_key] = _id\n",
    "        split_docs_ids.append(_id)\n",
    "    split_docs.extend(split_doc)  # 분할된 문서를 리스트에 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912dc49",
   "metadata": {},
   "source": [
    "분할된 문서의 개수를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"분할된 문서의 개수: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769298d",
   "metadata": {},
   "source": [
    "마지막으로 분할된 문서를 벡터 저장소에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 검색기의 벡터 저장소에 추가합니다.\n",
    "retriever.vectorstore.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9158831",
   "metadata": {},
   "source": [
    "`vectorstore` 객체의 `similarity_search` 메서드를 사용하여 유사도 검색을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "result_docs = vectorstore.similarity_search(\"Word2Vec의 정의가 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 결과 문서를 출력합니다.\n",
    "result_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64a80",
   "metadata": {},
   "source": [
    "`retriever` 객체의 `get_relevant_documents` 메서드를 사용하여 질문과 관련된 문서를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.get_relevant_documents(\"Word2Vec 의 정의가 뭐야?\")\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ef9cd",
   "metadata": {},
   "source": [
    "`retrieved_docs[0].page_content`의 길이를 반환합니다. 문서를 반환하기 때문에 페이지 내용의 길이는 청크보다 일반적으로 큽니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\n",
    "len(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d5f1b",
   "metadata": {},
   "source": [
    "## 가설 쿼리(Hypothetical Queries)\n",
    "\n",
    "LLM은 특정 문서에 대해 가정할 수 있는 질문 목록을 생성하는 데에도 사용될 수 있습니다.\n",
    "\n",
    "이렇게 생성된 질문들은 임베딩(embedding)될 수 있으며, 이를 통해 문서의 내용을 더욱 깊이 있게 탐색하고 이해할 수 있습니다.\n",
    "\n",
    "가정 질문 생성은 문서의 주요 주제와 개념을 파악하는 데 도움이 되며, 독자들이 문서 내용에 대해 더 많은 궁금증을 갖도록 유도할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7933e03",
   "metadata": {},
   "source": [
    "- `functions` 리스트에는 하나의 딕셔너리 요소가 포함되어 있습니다.\n",
    "- 딕셔너리는 `name`, `description`, `parameters` 키를 가지고 있습니다.\n",
    "- `name`은 함수의 이름을 나타내는 문자열입니다.\n",
    "- `description`은 함수의 설명을 나타내는 문자열입니다.\n",
    "- `parameters`는 함수의 매개변수를 정의하는 딕셔너리입니다.\n",
    "  - `type`은 매개변수의 타입을 나타내며, 여기서는 \"object\"로 설정되어 있습니다.\n",
    "  - `properties`는 객체의 속성을 정의하는 딕셔너리입니다.\n",
    "    - `questions`는 \"array\" 타입의 속성으로, 각 요소는 \"string\" 타입입니다.\n",
    "  - `required`는 필수 속성을 나타내는 리스트이며, 여기서는 `questions`가 필수로 지정되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # 함수의 이름을 지정합니다.\n",
    "        \"description\": \"Generate hypothetical questions\",  # 함수에 대한 설명을 작성합니다.\n",
    "        \"parameters\": {  # 함수의 매개변수를 정의합니다.\n",
    "            \"type\": \"object\",  # 매개변수의 타입을 객체로 지정합니다.\n",
    "            \"properties\": {  # 객체의 속성을 정의합니다.\n",
    "                \"questions\": {  # 'questions' 속성을 정의합니다.\n",
    "                    \"type\": \"array\",  # 'questions'의 타입을 배열로 지정합니다.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # 배열의 요소 타입을 문자열로 지정합니다.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # 필수 매개변수로 'questions'를 지정합니다.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa557a",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate`을 사용하여 주어진 문서를 기반으로 3개의 가상 질문을 생성하는 프롬프트 템플릿을 정의합니다.\n",
    "\n",
    "- `ChatOpenAI`를 사용하여 GPT 모델을 초기화하고, `functions`와 `function_call`을 설정하여 가상 질문 생성 함수를 호출합니다.\n",
    "- `JsonKeyOutputFunctionsParser`를 사용하여 생성된 가상 질문을 파싱하고, `questions` 키에 해당하는 값을 추출합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청합니다. 이 숫자는 조정될 수 있습니다.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. Answer in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4-turbo-preview\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # 출력에서 \"questions\" 키에 해당하는 값을 추출합니다.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b789211",
   "metadata": {},
   "source": [
    "`chain.invoke(docs[0])` 호출하여 첫 번째 문서에 대한 답변을 출력합니다.\n",
    "\n",
    "- 출력은 생성한 3개의 가설 쿼리(Hypothetical Queries) 가 담겨 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cda3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 문서에 대해 체인을 실행합니다.\n",
    "chain.invoke(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ff912",
   "metadata": {},
   "source": [
    "`chain.batch` 메서드를 사용하여 `docs` 데이터에 대해 동시에 여러 개의 요청을 처리합니다.\n",
    "\n",
    "- `docs` 매개변수는 처리할 문서 데이터를 나타냅니다.\n",
    "- `max_concurrency` 매개변수는 동시에 처리할 수 있는 최대 요청 수를 지정합니다. 이 예시에서는 5로 설정되어 있습니다.\n",
    "- 이 메서드는 `docs` 데이터의 각 항목에 대해 `chain` 객체의 작업을 수행하고, 최대 5개의 요청을 동시에 처리합니다.\n",
    "- 처리 결과는 `hypothetical_questions` 변수에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac642190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 목록에 대해 가설적 질문을 일괄 처리하여 생성합니다. 최대 동시성은 5로 설정되어 있습니다.\n",
    "hypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02840bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hypothetical_questions[0])\n",
    "print(hypothetical_questions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ded0",
   "metadata": {},
   "source": [
    "아래는 이전에 진행했던 방식과 동일하게 생성한 가설 쿼리(Hypothetical Queries) 를 벡터저장소에 저장하는 과정입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]  # 문서 ID 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8a6b7",
   "metadata": {},
   "source": [
    "`question_docs` 리스트에 메타데이터(문서 ID) 를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# hypothetical_questions 리스트를 순회하면서 인덱스와 질문 리스트를 가져옵니다.\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(  # question_docs 리스트에 Document 객체를 추가합니다.\n",
    "        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하고, 메타데이터에 해당 질문의 문서 ID를 포함시킵니다.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a8e5f",
   "metadata": {},
   "source": [
    "가설 쿼리를 문서에 추가하고, 원본 문서를 `docstore` 에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ecf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    question_docs\n",
    ")  # 질문 문서를 벡터 저장소에 추가합니다.\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb5835",
   "metadata": {},
   "source": [
    "`vectorstore` 객체의 `similarity_search` 메서드를 사용하여 유사도 검색을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9afb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 문서를 벡터 저장소에서 검색합니다.\n",
    "result_docs = vectorstore.similarity_search(\"Word2Vec에 대한 정의는 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce41e6",
   "metadata": {},
   "source": [
    "아래는 유사도 검색 결과입니다.\n",
    "\n",
    "여기서는 생성한 가설 쿼리만 추가해 놓은 상태이기 때문에, 생성한 가설 쿼리 중 유사도가 가장 높은 문서를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c33bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색 결과를 출력합니다.\n",
    "result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbb03d",
   "metadata": {},
   "source": [
    "이전 단계에서 분할한 문서도 벡터저장소에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c84315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 검색기의 벡터 저장소에 추가합니다.\n",
    "retriever.vectorstore.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88722c7",
   "metadata": {},
   "source": [
    "`retriever` 객체의 `get_relevant_documents` 메서드를 사용하여 쿼리와 관련된 문서를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.get_relevant_documents(\"Word2Vec에 대한 정의가 뭐야?\")\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4bf86",
   "metadata": {},
   "source": [
    "검색 결과인 `retrieved_docs[0].page_content`의 길이를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74403220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\n",
    "len(retrieved_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
