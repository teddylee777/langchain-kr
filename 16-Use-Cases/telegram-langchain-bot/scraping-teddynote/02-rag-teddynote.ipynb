{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlK44FRyPYaR"
   },
   "source": [
    "# <ë­ì²´ì¸LangChain ë…¸íŠ¸> RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;ë­ì²´ì¸LangChain ë…¸íŠ¸&gt; - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·</td>\n",
       "      <td>https://wikidocs.net//book/14314</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH01 LangChain ì‹œì‘í•˜ê¸°</td>\n",
       "      <td>https://wikidocs.net/233341</td>\n",
       "      <td># CH01 LangChain ì‹œì‘í•˜ê¸°\\n\\nLangChainì€ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸</td>\n",
       "      <td>https://wikidocs.net/233342</td>\n",
       "      <td># 01. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸\\n\\n## OpenAI API í‚¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬)</td>\n",
       "      <td>https://wikidocs.net/233343</td>\n",
       "      <td># 02. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬)\\n\\n```\\nCopy#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03. LangChain Expression Language(LCEL)</td>\n",
       "      <td>https://wikidocs.net/233344</td>\n",
       "      <td># 03. LangChain Expression Language(LCEL)\\n\\n#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>CH15 íŒŒì¸íŠœë‹(Fine Tuning)</td>\n",
       "      <td>https://wikidocs.net/233783</td>\n",
       "      <td># CH15 íŒŒì¸íŠœë‹(Fine Tuning)\\n\\níŒŒì¸íŠœë‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CH16 ì‚¬ë¡€(Use Cases)</td>\n",
       "      <td>https://wikidocs.net/233784</td>\n",
       "      <td># CH16 ì‚¬ë¡€(Use Cases)\\n\\nuse cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools)</td>\n",
       "      <td>https://wikidocs.net/234162</td>\n",
       "      <td># 01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CH17 LangGraph</td>\n",
       "      <td>https://wikidocs.net/233785</td>\n",
       "      <td># CH17 LangGraph\\n\\nLangGraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>01. Chain of Table for Multiple Tables</td>\n",
       "      <td>https://wikidocs.net/233325</td>\n",
       "      <td># 01. Chain of Table for Multiple Tables\\n\\nCY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0             <ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·   \n",
       "1                                 CH01 LangChain ì‹œì‘í•˜ê¸°    \n",
       "2                            01. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸   \n",
       "3                       02. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬)   \n",
       "4              03. LangChain Expression Language(LCEL)   \n",
       "..                                                 ...   \n",
       "102                             CH15 íŒŒì¸íŠœë‹(Fine Tuning)   \n",
       "103                                 CH16 ì‚¬ë¡€(Use Cases)   \n",
       "104  01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools)   \n",
       "105                                     CH17 LangGraph   \n",
       "106             01. Chain of Table for Multiple Tables   \n",
       "\n",
       "                               source  \\\n",
       "0    https://wikidocs.net//book/14314   \n",
       "1         https://wikidocs.net/233341   \n",
       "2         https://wikidocs.net/233342   \n",
       "3         https://wikidocs.net/233343   \n",
       "4         https://wikidocs.net/233344   \n",
       "..                                ...   \n",
       "102       https://wikidocs.net/233783   \n",
       "103       https://wikidocs.net/233784   \n",
       "104       https://wikidocs.net/234162   \n",
       "105       https://wikidocs.net/233785   \n",
       "106       https://wikidocs.net/233325   \n",
       "\n",
       "                                               content  \n",
       "0                                                       \n",
       "1    # CH01 LangChain ì‹œì‘í•˜ê¸°\\n\\nLangChainì€ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•´...  \n",
       "2    # 01. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸\\n\\n## OpenAI API í‚¤...  \n",
       "3    # 02. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬)\\n\\n```\\nCopy#...  \n",
       "4    # 03. LangChain Expression Language(LCEL)\\n\\n#...  \n",
       "..                                                 ...  \n",
       "102                   # CH15 íŒŒì¸íŠœë‹(Fine Tuning)\\n\\níŒŒì¸íŠœë‹  \n",
       "103                  # CH16 ì‚¬ë¡€(Use Cases)\\n\\nuse cases  \n",
       "104  # 01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with T...  \n",
       "105                      # CH17 LangGraph\\n\\nLangGraph  \n",
       "106  # 01. Chain of Table for Multiple Tables\\n\\nCY...  \n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "df = pd.read_csv('data_list_with_content.csv')\n",
    "\n",
    "# 'content' ì—´ì˜ NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "df['content'] = df['content'].fillna('')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶„í• ëœ í…Œë””ë…¸íŠ¸ íŒŒì¼ì˜ ê°œìˆ˜: 825\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row['content']):\n",
    "        continue\n",
    "    chunks = text_splitter.split_text(row['content'])\n",
    "    for chunk in chunks:\n",
    "        documents.append(Document(page_content=chunk, metadata={\"title\": row['title'], \"source\": row['source']}))\n",
    "\n",
    "print(f\"ë¶„í• ëœ í…Œë””ë…¸íŠ¸ íŒŒì¼ì˜ ê°œìˆ˜: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_openaiì™€ langchainì˜ í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "# ë¡œì»¬ íŒŒì¼ ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ LocalFileStore ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# './cache/' ë””ë ‰í† ë¦¬ì— ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ëª¨ë¸ëª…ìœ¼ë¡œ \"text-embedding-3-small\"ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", disallowed_special=())\n",
    "\n",
    "# CacheBackedEmbeddingsë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ê³„ì‚° ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤.\n",
    "# ì´ë ‡ê²Œ í•˜ë©´ ì„ë² ë”©ì„ ì—¬ëŸ¬ ë²ˆ ê³„ì‚°í•  í•„ìš” ì—†ì´ í•œ ë²ˆ ê³„ì‚°ëœ ê°’ì„ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, store, namespace=embeddings.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_community ëª¨ë“ˆì—ì„œ FAISS í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ë¡œì»¬ì— ì €ì¥í•  FAISS ì¸ë±ìŠ¤ì˜ í´ë” ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "FAISS_DB_INDEX = \"teddynote_faiss\"\n",
    "\n",
    "# combined_documents ë¬¸ì„œë“¤ê³¼ cached_embeddings ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ FAISS ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "db = FAISS.from_documents(documents, cached_embeddings)\n",
    "\n",
    "# ìƒì„±ëœ ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§€ì •í•œ í´ë”ì— ë¡œì»¬ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "db.save_local(folder_path=FAISS_DB_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS í´ë˜ìŠ¤ì˜ load_local ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ëœ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "db = FAISS.load_local(\n",
    "    FAISS_DB_INDEX,  # ë¡œë“œí•  FAISS ì¸ë±ìŠ¤ì˜ ë””ë ‰í† ë¦¬ ì´ë¦„\n",
    "    cached_embeddings,  # ì„ë² ë”© ì •ë³´ë¥¼ ì œê³µ\n",
    "    allow_dangerous_deserialization=True,  # ì—­ì§ë ¬í™”ë¥¼ í—ˆìš©í•˜ëŠ” ì˜µì…˜\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMRì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "faiss_retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"ë‹¹ì‹ ì€ 20ë…„ì°¨ AI ê°œë°œìì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ ìµœëŒ€í•œ ë¬¸ì„œì˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ë¬¸ì„œëŠ” Python ì½”ë“œì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ë‹µë³€ì„ ì‘ì„±í•  ë•Œì—ëŠ” Python ì½”ë“œì— ëŒ€í•œ ìƒì„¸í•œ code snippetì„ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ë‹µë³€í•˜ê³ , í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, \"ë¬¸ì„œì— ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.\"ë¼ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
    "ë‹µë³€ì€ ì¶œì²˜(source)ë¥¼ ë°˜ë“œì‹œ í‘œê¸°í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "#ì°¸ê³ ë¬¸ì„œ:\n",
    "{context}\n",
    "\n",
    "#ì§ˆë¬¸:\n",
    "{question}\n",
    "\n",
    "#ë‹µë³€: \n",
    "\n",
    "ì¶œì²˜:\n",
    "- source1\n",
    "- source2\n",
    "- ...                             \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ").configurable_alternatives(\n",
    "    # ì´ í•„ë“œì— idë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
    "    # ìµœì¢… ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ êµ¬ì„±í•  ë•Œ, ì´ idë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ í•„ë“œë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # ê¸°ë³¸ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    default_key=\"gpt4\",\n",
    "    claude=ChatAnthropic(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        temperature=0,\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    ),\n",
    "    gpt3=ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    ),\n",
    "    ollama=ChatOllama(\n",
    "        model=\"EEVE-Korean-10.8B:long\",\n",
    "        callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "rag_chain = (\n",
    "    {\"context\": faiss_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromptTemplateì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤. PromptTemplateì€ íŠ¹ì • í˜•ì‹ì˜ ë¬¸ìì—´ í…œí”Œë¦¿ì„ ì •ì˜í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ë¬¸ìì—´ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤. ì£¼ë¡œ ë³€ìˆ˜ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ í…œí”Œë¦¿ì„ ì •ì˜í•˜ê³ , ì´ ë³€ìˆ˜ë“¤ì— ê°’ì„ í• ë‹¹í•˜ì—¬ ìµœì¢… ë¬¸ìì—´ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "### ê¸°ë³¸ ì‚¬ìš©ë²•\n",
      "\n",
      "1. **PromptTemplate ì •ì˜í•˜ê¸°**\n",
      "\n",
      "   ë¨¼ì €, ë³€ìˆ˜ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤. ë³€ìˆ˜ëŠ” ì¤‘ê´„í˜¸ `{}`ë¡œ ë¬¶ì–´ì„œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   from langchain_core.prompts import PromptTemplate\n",
      "   \n",
      "   template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
      "   ```\n",
      "\n",
      "2. **PromptTemplate ê°ì²´ ìƒì„±í•˜ê¸°**\n",
      "\n",
      "   ì •ì˜í•œ í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì‚¬ìš©í•˜ì—¬ PromptTemplate ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë•Œ, `from_template` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   prompt = PromptTemplate.from_template(template)\n",
      "   ```\n",
      "\n",
      "3. **ë³€ìˆ˜ì— ê°’ í• ë‹¹í•˜ê¸°**\n",
      "\n",
      "   ìƒì„±ëœ PromptTemplate ê°ì²´ì— ë³€ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ `format` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ê³ , ë³€ìˆ˜ëª…ì„ í‚¤ì›Œë“œ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   prompt = prompt.format(country=\"ëŒ€í•œë¯¼êµ­\")\n",
      "   ```\n",
      "\n",
      "4. **ìµœì¢… ë¬¸ìì—´ ìƒì„±í•˜ê¸°**\n",
      "\n",
      "   ë³€ìˆ˜ì— ê°’ì´ í• ë‹¹ëœ í›„, PromptTemplate ê°ì²´ëŠ” ìµœì¢… ë¬¸ìì—´ì„ í¬í•¨í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ ë¬¸ìì—´ì€ PromptTemplate ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ì¶œë ¥í•¨ìœ¼ë¡œì¨ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   print(prompt)  # 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'\n",
      "   ```\n",
      "\n",
      "### ì¶”ê°€ ê¸°ëŠ¥\n",
      "\n",
      "- **ë³€ìˆ˜ ìœ íš¨ì„± ê²€ì‚¬**\n",
      "\n",
      "  PromptTemplateì„ ìƒì„±í•  ë•Œ `input_variables` ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ í…œí”Œë¦¿ì— í¬í•¨ë  ë³€ìˆ˜ë“¤ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³€ìˆ˜ëª…ì˜ ì˜¤íƒ€ ë“±ì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "  ```python\n",
      "  prompt = PromptTemplate(\n",
      "      template=template,\n",
      "      input_variables=[\"country\"],\n",
      "  )\n",
      "  ```\n",
      "\n",
      "- **ë¶€ë¶„ ë³€ìˆ˜ ì„¤ì •**\n",
      "\n",
      "  ì¼ë¶€ ë³€ìˆ˜ì— ë¯¸ë¦¬ ê°’ì„ í• ë‹¹í•˜ê³ , ë‚˜ë¨¸ì§€ ë³€ìˆ˜ì—ëŠ” ë‚˜ì¤‘ì— ê°’ì„ í• ë‹¹í•˜ê³  ì‹¶ì„ ë•Œ `partial_variables` ì¸ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "  ```python\n",
      "  template = \"{country1}ê³¼ {country2}ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?\"\n",
      "  prompt = PromptTemplate(\n",
      "      template=template,\n",
      "      input_variables=[\"country1\"],\n",
      "      partial_variables={\"country2\": \"ë¯¸êµ­\"}\n",
      "  )\n",
      "  ```\n",
      "\n",
      "ì´ëŸ¬í•œ ë°©ë²•ìœ¼ë¡œ PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ ë¬¸ìì—´ì„ ìƒì„±í•˜ê³ , ë‹¤ì–‘í•œ ìƒí™©ì— ë§ê²Œ ë¬¸ìì—´ í¬ë§·ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶œì²˜: [https://wikidocs.net/233351](https://wikidocs.net/233351)"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.with_config(configurable={\"llm\": \"gpt4\"}).invoke(\n",
    "    \"PromptTemplate ì‚¬ìš©ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
