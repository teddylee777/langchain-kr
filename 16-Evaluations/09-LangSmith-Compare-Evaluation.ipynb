{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc39cad",
   "metadata": {},
   "source": [
    "# ì‹¤í—˜(Experiment) í‰ê°€ ë¹„êµ\n",
    "\n",
    "LangSmith ì—ì„œ ì œê³µí•˜ëŠ” Compare ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "- https://docs.smith.langchain.com/cookbook/tracing-examples/traceable#using-the-decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a30a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì¹˜\n",
    "# !pip install -qU langsmith langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75d1492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633d9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH16-Evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c8411",
   "metadata": {},
   "source": [
    "## RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f17eb",
   "metadata": {},
   "source": [
    "í…ŒìŠ¤íŠ¸ì— í™œìš©í•  RAG ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb9be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myrag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±\n",
    "def ask_question_with_llm(llm):\n",
    "    # PDFRAG ê°ì²´ ìƒì„±\n",
    "    rag = PDFRAG(\n",
    "        \"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\",\n",
    "        llm,\n",
    "    )\n",
    "\n",
    "    # ê²€ìƒ‰ê¸°(retriever) ìƒì„±\n",
    "    retriever = rag.create_retriever()\n",
    "\n",
    "    # ì²´ì¸(chain) ìƒì„±\n",
    "    rag_chain = rag.create_chain(retriever)\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"]),\n",
    "        }\n",
    "\n",
    "    return _ask_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb60ff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë„ì›€ì´ ë˜ê³  ì¡´ì¤‘í•˜ëŠ” ì¡°ìˆ˜ë¡œì„œ ì—¬ëŸ¬ë¶„ì´ ê°€ì§„ ì§ˆë¬¸ì— ìµœì„ ì„ ë‹¤í•´ ë‹µë³€í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©° ì•ˆì „í•˜ê³  ì‚¬íšŒì  í¸ê²¬ì´ ì—†ë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ì œê°€ ì œê³µí•  ìˆ˜ ìˆëŠ” ì •ë³´ì— í•œê³„ê°€ ìˆì„ ìˆ˜ë„ ìˆì§€ë§Œ, í•­ìƒ ì •ì§í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í• ê²Œìš”. ë§Œì•½ ì§ˆë¬¸ì´ ë§ì´ ë˜ì§€ ì•Šê±°ë‚˜ í•´ë¡­ê±°ë‚˜ ë¹„ìœ¤ë¦¬ì ì¸ ë‚´ìš©ì„ ë‹´ê³  ìˆë‹¤ë©´, ëŒ€ì‹  ì™œ ê·¸ëŸ°ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ ë“œë¦´ ê²ƒì…ë‹ˆë‹¤. \\n\\nì‹œì‘í•´ë³¼ê¹Œìš”! ê¶ê¸ˆí•œ ì ì´ ìˆê±°ë‚˜ ë„ì™€ë“œë¦´ ì¼ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ˜Š', response_metadata={'model': 'EEVE-Korean-10.8B:latest', 'created_at': '2024-09-19T10:47:07.198627Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 19967110416, 'load_duration': 15875755666, 'prompt_eval_count': 50, 'prompt_eval_duration': 172501000, 'eval_count': 106, 'eval_duration': 3915680000}, id='run-6bb08ee1-77ff-4ab1-be72-5f72dd277964-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "ollama = ChatOllama(model=\"EEVE-Korean-10.8B:latest\")\n",
    "\n",
    "# Ollama ëª¨ë¸ í˜¸ì¶œ\n",
    "ollama.invoke(\"ì•ˆë…•í•˜ì„¸ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549f7aa",
   "metadata": {},
   "source": [
    "GPT-4o-mini ëª¨ë¸ê³¼ Ollama ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95e0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "ollama_chain = ask_question_with_llm(ChatOllama(model=\"EEVE-Korean-10.8B:latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1a889",
   "metadata": {},
   "source": [
    "GPT-4o-mini ëª¨ë¸ê³¼ Ollama ëª¨ë¸ì„ í™œìš©í•œ ë‹µë³€ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "2ê°œì˜ ì²´ì¸ì— ëŒ€í•˜ì—¬ ê°ê° ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2fb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'MODEL_COMPARE_EVAL-23908367' at:\n",
      "https://smith.langchain.com/o/42ebd69b-2565-441c-b868-9709c2e20267/datasets/7be96c7d-41ca-4f3a-96da-7bf7c706e0a5/compare?selectedSessions=384e4d64-0af4-4874-86b9-66fd08943454\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dd67ef33e54c53bf7b1be8edc6b81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'MODEL_COMPARE_EVAL-a4a9f9ff' at:\n",
      "https://smith.langchain.com/o/42ebd69b-2565-441c-b868-9709c2e20267/datasets/7be96c7d-41ca-4f3a-96da-7bf7c706e0a5/compare?selectedSessions=4eb8208b-ba85-45e0-b923-eea88fff7684\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09383973065f40d9ae6169e228500c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa í‰ê°€ì ìƒì„±\n",
    "cot_qa_evalulator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    config={\"llm\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)},\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": run.outputs[\"context\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "experiment_results1 = evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evalulator],\n",
    "    experiment_prefix=\"MODEL_COMPARE_EVAL\",\n",
    "    # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì§€ì •\n",
    "    metadata={\n",
    "        \"variant\": \"GPT-4o-mini í‰ê°€ (cot_qa)\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "experiment_results2 = evaluate(\n",
    "    ollama_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evalulator],\n",
    "    experiment_prefix=\"MODEL_COMPARE_EVAL\",\n",
    "    # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì§€ì •\n",
    "    metadata={\n",
    "        \"variant\": \"Ollama(EEVE-Korean-10.8B:latest) í‰ê°€ (cot_qa)\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc3f5a7",
   "metadata": {},
   "source": [
    "ê²°ê³¼ë¥¼ ê²€ì‚¬í•˜ê¸° ìœ„í•´ ë¹„êµ ë³´ê¸°ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2709e",
   "metadata": {},
   "source": [
    "**ë¹„êµ ë³´ê¸°ë¥¼ í•˜ëŠ” ë°©ë²•**\n",
    "\n",
    "![](./assets/eval-01.png)\n",
    "\n",
    "![](./assets/eval-02.png)\n",
    "\n",
    "1. Dataset ì˜ Experiment íƒ­ì—ì„œ ë¹„êµí•˜ê³  ì‹¶ì€ ì‹¤í—˜ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "2. í•˜ë‹¨ì˜ \"Compare\" ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.\n",
    "3. ë¹„êµ ë³´ê¸°ê°€ í‘œì‹œë©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
