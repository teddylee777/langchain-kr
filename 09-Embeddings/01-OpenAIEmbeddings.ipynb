{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e46434a",
   "metadata": {},
   "source": [
    "# OpenAIEmbeddings\n",
    "\n",
    "문서 임베드(Embed documents)는 문서의 내용을 벡터 형태로 표현하는 과정을 의미합니다.\n",
    "\n",
    "이를 통해 문서의 의미론적 정보를 수치화할 수 있으며, 문서 간의 유사도 비교, 문서 분류, 검색 등 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
    "\n",
    "문서 임베드는 주로 사전 학습된 언어 모델을 사용하여 수행되며, 대표적인 예로는 BERT, GPT 등이 있습니다.\n",
    "\n",
    "이러한 모델들은 대규모 텍스트 데이터로 학습되어 문맥적 정보를 포착할 수 있기 때문에, 문서의 의미를 효과적으로 인코딩할 수 있습니다.\n",
    "\n",
    "문서 임베드 과정에서는 문서를 토큰화하고, 각 토큰을 언어 모델에 입력하여 해당 토큰의 임베딩 벡터를 얻습니다.\n",
    "\n",
    "이후 문서 전체의 임베딩 벡터를 계산하기 위해 토큰 임베딩 벡터들을 평균하거나 가중 평균하는 등의 방법을 사용할 수 있습니다.\n",
    "\n",
    "문서 임베드를 통해 얻은 벡터 표현은 문서 간의 유사도를 계산하는 데 사용될 수 있으며, 이는 문서 검색, 추천 시스템, 문서 클러스터링 등 다양한 응용 분야에서 활용됩니다.\n",
    "\n",
    "또한 임베딩 벡터를 기반으로 문서 분류나 감성 분석 등의 작업을 수행할 수 있습니다.\n",
    "\n",
    "문서 임베드는 자연어 처리 분야에서 중요한 역할을 하며, 대량의 문서를 효율적으로 처리하고 분석하는 데 핵심적인 기술로 자리잡고 있습니다.\n",
    "\n",
    "\n",
    "- [관련 문서](https://platform.openai.com/docs/guides/embeddings/embedding-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "먼저 langchain-openai를 설치하고 필요한 환경 변수를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1639feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b37773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3fe79",
   "metadata": {},
   "source": [
    "- `OpenAIEmbeddings` 클래스를 `langchain_openai` 모듈에서 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23453c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dafd0e",
   "metadata": {},
   "source": [
    "- OpenAIEmbeddings 클래스를 사용하여 임베딩 객체를 생성합니다.\n",
    "- 임베딩 모델로는 \"text-embedding-3-large\"를 사용합니다.\n",
    "- 이 모델은 OpenAI에서 제공하는 대규모 텍스트 임베딩 모델 중 하나입니다.\n",
    "- 생성된 `embeddings` 객체는 텍스트를 벡터로 변환하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f9fa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d694e0d",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00541ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fbebb",
   "metadata": {},
   "source": [
    "## 쿼리 임베딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08285a94",
   "metadata": {},
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "- `text` 매개변수로 전달된 텍스트를 입력으로 받습니다.\n",
    "- 텍스트를 임베딩 모델에 전달하여 해당 텍스트의 벡터 표현을 생성합니다.\n",
    "- 생성된 임베딩 벡터를 `query_result` 변수에 저장합니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적으로 유사한 텍스트를 찾거나 텍스트 간의 유사도를 계산하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "973c5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c80557",
   "metadata": {},
   "source": [
    "`query_result[:5]`는 `query_result` 리스트의 처음 5개 요소를 슬라이싱(slicing)하여 선택합니다.\n",
    "\n",
    "- 리스트 슬라이싱 문법인 `[start:end]`를 사용하여 리스트의 일부분을 추출합니다.\n",
    "- `start` 인덱스는 포함되고 `end` 인덱스는 제외됩니다.\n",
    "- `start`를 생략하면 리스트의 처음부터 슬라이싱합니다.\n",
    "- 따라서 `query_result[:5]`는 `query_result` 리스트의 인덱스 0부터 4까지의 요소를 선택하여 새로운 리스트를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af37ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.003218927512230862,\n",
       " -0.00790991377231665,\n",
       " -0.012806527680822976,\n",
       " 0.030056136583834044,\n",
       " 0.016404038761725557]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 5개 항목을 선택합니다.\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f8fbc",
   "metadata": {},
   "source": [
    "## 도큐먼트 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fcf40",
   "metadata": {},
   "source": [
    "`embeddings.embed_documents()` 함수를 사용하여 텍스트 문서를 임베딩합니다.\n",
    "\n",
    "- `[text]`를 인자로 전달하여 단일 문서를 리스트 형태로 임베딩 함수에 전달합니다.\n",
    "- 함수 호출 결과로 반환된 임베딩 벡터를 `doc_result` 변수에 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f5d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents(\n",
    "    [text]\n",
    ")  # 텍스트를 임베딩하여 문서 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdee91",
   "metadata": {},
   "source": [
    "`doc_result[0][:5]`는 `doc_result` 리스트의 첫 번째 요소에서 처음 5개의 문자를 슬라이싱하여 선택합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7565438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.003218927512230862,\n",
       " -0.00790991377231665,\n",
       " -0.012806527680822976,\n",
       " 0.030056136583834044,\n",
       " 0.016404038761725557]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 결과의 첫 번째 요소에서 처음 5개 항목을 선택합니다.\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f47ff",
   "metadata": {},
   "source": [
    "## 차원 지정\n",
    "\n",
    "`text-embedding-3` 모델 클래스를 사용하면 반환되는 임베딩의 크기를 지정할 수 있습니다.\n",
    "\n",
    "예를 들어, 기본적으로 `text-embedding-3-large`는 3072 차원의 임베딩을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb82bb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 결과의 첫 번째 요소의 길이를 반환합니다.\n",
    "len(doc_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60da32",
   "metadata": {},
   "source": [
    "하지만 `dimensions=1024`를 전달함으로써 임베딩의 크기를 1024로 줄일 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6e895",
   "metadata": {},
   "source": [
    "- OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 1024차원의 임베딩을 생성하는 `OpenAIEmbeddings` 객체를 초기화합니다.\n",
    "- `dimensions` 매개변수를 통해 임베딩 벡터의 차원을 1024로 설정합니다.\n",
    "- 생성된 `embeddings_1024` 객체를 사용하여 텍스트 데이터를 1024차원의 벡터로 변환할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdfa8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 1024차원의 임베딩을 생성하는 객체를 초기화합니다.\n",
    "embeddings_1024 = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\", dimensions=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf91cd",
   "metadata": {},
   "source": [
    "`embeddings_1024.embed_documents()` 함수를 사용하여 단일 텍스트(`text`)를 임베딩한 결과의 길이를 반환합니다.\n",
    "\n",
    "- `embeddings_1024.embed_documents()` 함수는 리스트 형태의 텍스트를 입력받아 각 텍스트에 대한 임베딩 벡터를 생성합니다.\n",
    "- `[text]`와 같이 단일 텍스트를 리스트로 감싸서 함수에 전달합니다.\n",
    "- 함수의 반환값은 임베딩 벡터들의 리스트입니다. 이 예시에서는 단일 텍스트를 임베딩했으므로 반환되는 리스트의 길이는 1입니다.\n",
    "- 반환된 리스트의 첫 번째 요소(`[0]`)는 `text`에 대한 임베딩 벡터입니다.\n",
    "- `len()` 함수를 사용하여 임베딩 벡터의 길이를 계산합니다.\n",
    "\n",
    "따라서 이 코드는 `text`를 임베딩한 벡터의 길이를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3fbcdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 텍스트를 임베딩하고 첫 번째 임베딩 벡터의 길이를 반환합니다.\n",
    "len(embeddings_1024.embed_documents([text])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8ca34",
   "metadata": {},
   "source": [
    "## 유사도 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dddbb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
    "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
    "sentence4 = \"Hi, nice to meet you.\"\n",
    "sentence5 = \"I like to eat apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8662aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79b0f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
    "embedded_sentences = embeddings_1024.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d9e24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58fbf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.9652] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
      "[유사도 0.8576] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5451] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1725] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.8402] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5340] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1857] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
      "[유사도 0.5856] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1575] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.2474] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
     ]
    }
   ],
   "source": [
    "# sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "# sentence2 = \"안녕하세요? 만나서 반가워요.\"\n",
    "# sentence3 = \"Hi, nice to meet you.\"\n",
    "# sentence4 = \"I like to eat apples.\"\n",
    "\n",
    "for i, sentence in enumerate(embedded_sentences):\n",
    "    for j, other_sentence in enumerate(embedded_sentences):\n",
    "        if i < j:\n",
    "            print(\n",
    "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
