{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff Documents Chain\n",
    "\n",
    "`stuff documents chain`(\"stuff\"ëŠ” \"ì±„ìš°ë‹¤\" ë˜ëŠ” \"ì±„ìš°ê¸° ìœ„í•´\"ì˜ ì˜ë¯¸)ëŠ” ë¬¸ì„œ ì²´ì¸ ì¤‘ ê°€ìž¥ ê°„ë‹¨í•œ ë°©ì‹ìž…ë‹ˆë‹¤. ë¬¸ì„œ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ëª¨ë‘ í”„ë¡¬í”„íŠ¸ì— ì‚½ìž…í•œ ë‹¤ìŒ, ê·¸ í”„ë¡¬í”„íŠ¸ë¥¼ LLMì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì²´ì¸ì€ ë¬¸ì„œê°€ ìž‘ê³  ëŒ€ë¶€ë¶„ì˜ í˜¸ì¶œì— ëª‡ ê°œë§Œ ì „ë‹¬ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://js.langchain.com/assets/images/stuff-818da4c66ee17911bc8861c089316579.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`langchain_community.chat_models`, `langchain_core.prompts`, `langchain.chains.combine_documents` ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í´ëž˜ìŠ¤ì™€ í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "`ChatOpenAI`, `ChatPromptTemplate`, ê·¸ë¦¬ê³  `create_stuff_documents_chain` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ìžë¡œë¶€í„° ìž…ë ¥ë°›ì€ ë¬¸ìž¥ì„ ìš”ì•½í•˜ëŠ” ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ í…œí”Œë¦¿ì€ ì‹œìŠ¤í…œì´ ì „ë¬¸ ìš”ì•½ê°€ ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ ìš”ì²­í•˜ê³ , ì‚¬ìš©ìžì—ê²Œ í•œêµ­ì–´ë¡œ ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•ì‹ì˜ ìš”ì•½, ê° ë¬¸ìž¥ì˜ ì˜ë¯¸ì— ë§žëŠ” ì´ëª¨ì§€ ì‚¬ìš©, ë‹¤ì–‘í•œ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ìš”ì•½ì„ ë” í¥ë¯¸ë¡­ê²Œ ë§Œë“¤ë¼ëŠ” ì§€ì‹œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchainhub langchain_openai langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert summarizer. Please summarize the following sentence.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='Please summarize the sentence according to the following request.\\nREQUEST:\\n1. Summarize the main points in bullet points in Korean.2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.3. Use various emojis to make the summary more interesting.\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert summarizer. Please summarize the following sentence.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Please summarize the sentence according to the following request.\"\n",
    "            \"\\nREQUEST:\\n\"\n",
    "            \"1. Summarize the main points in bullet points in Korean.\"\n",
    "            \"2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\"\n",
    "            \"3. Use various emojis to make the summary more interesting.\"\n",
    "            \"\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(í˜¹ì€ ì•„ëž˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë‚´ë ¤ë°›ìŠµë‹ˆë‹¤)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context'], template='Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points in KOREAN.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. Translate the summary into KOREAN if it is written in ENGLISH.\\n5. DO NOT translate any technical terms.\\n6. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TextLoader` ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ë¡œë“œí•˜ê³ , Documentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`langchain_community.document_loaders` ëª¨ë“ˆì—ì„œ `TextLoader` í´ëž˜ìŠ¤ë¥¼ ìž„í¬íŠ¸í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. `TextLoader` ì¸ìŠ¤í„´ìŠ¤ëŠ” íŠ¹ì • íŒŒì¼(`data/news.txt`)ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 1\n",
      "\n",
      "[ë©”íƒ€ë°ì´í„°]\n",
      "\n",
      "{'source': 'data/news.txt'}\n",
      "\n",
      "========= [ì•žë¶€ë¶„] ë¯¸ë¦¬ë³´ê¸° =========\n",
      "\n",
      "ì œëª©: \n",
      "AI2, ìƒì—… í™œìš©ê¹Œì§€ ìžìœ ë¡œìš´ 'ì§„ì§œ' ì˜¤í”ˆ ì†ŒìŠ¤ LLM 'ì˜¬ëª¨' ì¶œì‹œ\n",
      "\n",
      "ë‚´ìš©:\n",
      "ì•¨ëŸ°AIì—°êµ¬ì†Œ(AI2)ê°€ ì™„ì „í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM) 'ì˜¬ëª¨(OLMo)â€™ë¥¼ ì¶œì‹œí–ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘, í•™ìŠµ, ë°°í¬ì˜ ì „ ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ê³µê°œí•œ ë°ë‹¤ ìƒì—…ì  ì‚¬ìš©ê¹Œì§€ í—ˆìš©í•œ ì§„ì •í•œ ì˜ë¯¸ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì´ë¼ëŠ” í‰ê°€ë‹¤.\n",
      "ë²¤ì²˜ë¹„íŠ¸ëŠ” 1ì¼(í˜„ì§€ì‹œê°„) ë¹„ì˜ë¦¬ ë¯¼ê°„ AI ì—°êµ¬ê¸°ê´€ì¸ AI2ê°€ â€˜ìµœì´ˆì˜ ì§„ì •í•œ ì˜¤í”ˆ ì†ŒìŠ¤ LLM ë° í”„ë ˆìž„ì›Œí¬â€™ë¼ê³  ì†Œê°œí•œ â€˜ì˜¬ëª¨â€™ë¥¼ ì¶œì‹œí–ˆë‹¤ê³  ë³´ë„í–ˆë‹¤. \n",
      "ì´ì— ë”°ë¥´ë©´ ì˜¬ëª¨ëŠ” ëª¨ë¸ ì½”ë“œì™€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¿ë§Œ ì•„ë‹ˆë¼ í›ˆë ¨ ì½”ë“œ, í›ˆë ¨ ë°ì´í„°, ê´€ë ¨ íˆ´í‚· ë° í‰ê°€ íˆ´í‚·ë„ ì œê³µí•œë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì–´ë–»ê²Œ êµ¬ì¶•ë˜ì—ˆëŠ”ì§€ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„, LLMì˜ ìž‘ë™ ë°©ì‹ê³¼ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì›ë¦¬ë¥¼ ë” ìž˜ ì´í•´í•  ìˆ˜ ìžˆë‹¤. \n",
      "ì˜¬ëª¨ í”„ë ˆìž„ì›Œí¬ëŠ” 70ì–µ ë§¤ê°œë³€ìˆ˜ì˜ â€˜ì˜¬ëª¨ 7Bâ€™ ë“± 4ê°€ì§€ ë³€í˜• ëª¨ë¸ê³¼ 10ì–µ ë§¤ê°œë³€ìˆ˜ì˜ â€˜ì˜¬ëª¨ 1Bâ€™ ëª¨ë¸ì„ ì œê³µí•œë‹¤. ëª¨ë¸ë“¤ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•´ \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/news.txt\")\n",
    "docs = loader.load()\n",
    "print(f\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\\n\")\n",
    "print(\"[ë©”íƒ€ë°ì´í„°]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [ì•žë¶€ë¶„] ë¯¸ë¦¬ë³´ê¸° =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MyCallbackHandler` í´ëž˜ìŠ¤ëŠ” `BaseCallbackHandler`ë¥¼ ìƒì†ë°›ì•„, ì–¸ì–´ ëª¨ë¸ì´ ìƒˆë¡œìš´ í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ í•´ë‹¹ í† í°ì„ ì¶œë ¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "`ChatOpenAI` ê°ì²´ëŠ” GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì™€ ë‚®ì€ ì˜¨ë„ ì„¤ì •ì„ í†µí•´ ë” ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ ê°ì²´ëŠ” ì½œë°±ìœ¼ë¡œ `MyCallbackHandler` ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, `create_stuff_documents_chain` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìƒì„± ì²´ì¸ì„ ë§Œë“¤ê³ , ì´ ì²´ì¸ì„ í†µí•´ ì£¼ì–´ì§„ ë¬¸ë§¥(`docs`)ì— ëŒ€í•œ ì‘ë‹µ(`answer`)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ ì•¨ëŸ°AIì—°êµ¬ì†Œ(AI2)ê°€ 'ì˜¬ëª¨(OLMo)'ë¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì„ ì¶œì‹œí–ˆë‹¤.\n",
      "ðŸ” ì˜¬ëª¨ëŠ” ë°ì´í„° ìˆ˜ì§‘, í•™ìŠµ, ë°°í¬ì˜ ì „ ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ê³µê°œí•˜ê³  ìƒì—…ì  ì‚¬ìš©ê¹Œì§€ í—ˆìš©í•˜ëŠ” ì§„ì •í•œ ì˜ë¯¸ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì´ë‹¤.\n",
      "ðŸ”§ ì˜¬ëª¨ëŠ” ëª¨ë¸ ì½”ë“œ, ëª¨ë¸ ê°€ì¤‘ì¹˜, í›ˆë ¨ ì½”ë“œ, í›ˆë ¨ ë°ì´í„°, ê´€ë ¨ íˆ´í‚· ë° í‰ê°€ íˆ´í‚·ì„ ì œê³µí•œë‹¤.\n",
      "ðŸ“š ì˜¬ëª¨ í”„ë ˆìž„ì›Œí¬ì—ëŠ” 'ì˜¬ëª¨ 7B'ì™€ 'ì˜¬ëª¨ 1B' ë“± 4ê°€ì§€ ë³€í˜• ëª¨ë¸ì´ í¬í•¨ë˜ì–´ ìžˆë‹¤.\n",
      "ðŸ’¡ ì˜¬ëª¨ëŠ” AI2ì˜ 'ëŒë§ˆ(Dolma)' ë°ì´í„° ì„¸íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ìƒì—…ì  í™œìš©ì— ì œí•œì´ ì—†ëŠ” ì•„íŒŒì¹˜ 2.0 ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¥¸ë‹¤.\n",
      "ðŸŒ ì˜¬ëª¨ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ì—ì„œ ìƒì—…ìš© ì œí’ˆê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.\n",
      "ðŸ”§ AI2ëŠ” ì˜¬ëª¨ë¥¼ ê³„ì†í•´ì„œ í–¥ìƒì‹œí‚¬ ì˜ˆì •ì´ë©°, ì˜¬ëª¨ì˜ ì¶œì‹œëŠ” AI ëª¨ë¸ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ë¥¼ ìœ„í•œ ê¸°ë°˜ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ë‹¤.\n",
      "ðŸ‘¨â€ðŸ’» ì–€ ë¥´ì¿¤ ë©”íƒ€ ìˆ˜ì„ ê³¼í•™ìžëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ë°˜ ëª¨ë¸ì´ AIì˜ í˜ì‹ ê³¼ ê°œë°œì„ ì´‰ì§„í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ê³  ë§í–ˆë‹¤.\n",
      "ðŸ”— ì˜¬ëª¨ì— ëŒ€í•œ ëª¨ë“  ë¦¬ì†ŒìŠ¤ëŠ” ê¹ƒí—ˆë¸Œ ë° í—ˆê¹…íŽ˜ì´ìŠ¤ì—ì„œ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class MyCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    temperature=0.01,\n",
    "    callbacks=[MyCallbackHandler()],\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "answer = chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
